{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"colab.research.google.com/github/usamireko/G2PTrainer/blob/main/G2PTrainer_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a notebook for training G2P files for OpenUtau, based off a modified version of the code found on OpenUTAU\n",
        "\n",
        "The original code can be found [here](https://github.com/stakira/OpenUtau/tree/master/py).\n",
        "\n",
        "This notebook is an edited copy of LotteV and Mlo7Ghinsan, edited by [usamireko](https://github.com/usamireko)"
      ],
      "metadata": {
        "id": "kJ2JAE6pYVrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "WN8XxMnEZZOA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH6eQUDIXpKC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title # Mount Google Drive and Setup\n",
        "\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output, display, HTML\n",
        "\n",
        "!rm -rf /content/sample_data\n",
        "drive.mount(\"/content/drive\")\n",
        "!git clone https://github.com/usamireko/G2PTrainer.git\n",
        "#thank you lotte <3\n",
        "!pip install antlr4-python3-runtime==4.9.*\n",
        "!pip install hydra-core==1.3.2 omegaconf==2.3.0 -q #that warning popup is annoying\n",
        "!pip install torch torchaudio\n",
        "!pip install editdistance\n",
        "!pip install tqdm==4.65.0\n",
        "!pip install onnx\n",
        "!pip install pytorch_optimizer\n",
        "!pip install PyYAML\n",
        "\n",
        "%cd /content/G2PTrainer\n",
        "\n",
        "clear_output()\n",
        "print(\"Done!\")\n",
        "display(HTML('''\n",
        "<div style=\"text-align:center;\">\n",
        "  <img src=\"https://files.catbox.moe/qcrz23.gif\" alt=\"Snow\" style=\"height:30%;\">\n",
        "</div>\n",
        "'''))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9j8n5pfgb1ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input dictionary\n",
        "from IPython.display import clear_output\n",
        "%cd /content/g2p\n",
        "import os\n",
        "if not os.path.exists(\"/content/user_g2p_data\"):\n",
        "    os.makedirs(\"/content/user_g2p_data\")\n",
        "clear_output()\n",
        "import sys\n",
        "import re\n",
        "import torch\n",
        "import hydra\n",
        "import yaml\n",
        "from omegaconf import OmegaConf\n",
        "sys.path.append(os.path.abspath('.'))\n",
        "from dataset import SphinxDataset\n",
        "from trainer import G2pTrainer\n",
        "from model import GreedyG2p\n",
        "\n",
        "def train(trainer):\n",
        "    print('training...')\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "def export(trainer, model_path, onnx_path):\n",
        "    print('exporting model...')\n",
        "    trainer.model.load_state_dict(torch.load(model_path))\n",
        "    trainer.model.cpu()\n",
        "    greedy = GreedyG2p(trainer.model.max_len,\n",
        "                       trainer.model.encoder, trainer.model.decoder)\n",
        "    greedy.export(onnx_path)\n",
        "\n",
        "    print('testing...')\n",
        "    trainer.test('test_log.txt')\n",
        "\n",
        "#@markdown input dictionary (can be dict.txt or dsdict.yaml)\n",
        "dict_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown input model save location\n",
        "save_path = \"\" # @param {type:\"string\"}\n",
        "if not save_path:\n",
        "    raise ValueError(\"Empty save_path, please specify a path to save your model\")\n",
        "else:\n",
        "    pass\n",
        "\n",
        "user_dict_path = save_path +\"/user_dictionary.txt\" #cleaned dict\n",
        "user_config = save_path + \"/config.yaml\" #generated config\n",
        "user_phonemes = save_path + \"/phones.txt\" #yea phoneme list yea poosay\n",
        "\n",
        "default_config = {\n",
        "    \"model\": {\n",
        "        \"_target_\": \"model.G2p\",\n",
        "        \"max_len\": 48,\n",
        "        \"encoder\": {\n",
        "            \"_target_\": \"model.Encoder\",\n",
        "            \"graphemes\": [],\n",
        "            \"d_model\": 64,\n",
        "            \"d_hidden\": 128,\n",
        "            \"num_layers\": 2,\n",
        "            \"dropout\": 0.1\n",
        "        },\n",
        "        \"decoder\": {\n",
        "            \"_target_\": \"model.Decoder\",\n",
        "            \"phonemes\": [],\n",
        "            \"d_model\": 64,\n",
        "            \"d_hidden\": 128,\n",
        "            \"num_layers\": 2,\n",
        "            \"dropout\": 0.1\n",
        "        }\n",
        "    },\n",
        "    \"optimizer\": {\n",
        "        \"_target_\": \"torch.optim.AdamW\",\n",
        "        \"lr\": 0.001,\n",
        "        \"betas\": [0.9, 0.999],\n",
        "        \"eps\": 1e-08,\n",
        "        \"weight_decay\": 0.01,\n",
        "    },\n",
        "    \"lr_scheduler\": {\n",
        "        \"_target_\": \"torch.optim.lr_scheduler.ReduceLROnPlateau\",\n",
        "        \"mode\": \"min\",\n",
        "        \"factor\": 0.4,\n",
        "        \"patience\": 5,\n",
        "        \"min_lr\": 1e-6,\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(user_config, \"w\") as cfg:\n",
        "    yaml.dump(default_config, cfg)\n",
        "\n",
        "if dict_path:\n",
        "    pass\n",
        "else:\n",
        "    raise ValueError(\"Please input path to your dictionary\")\n",
        "\n",
        "if dict_path.endswith(\".txt\"):\n",
        "    print(\"using txt format\")\n",
        "    with open(dict_path, \"r\", encoding = \"utf-8\") as dict:\n",
        "        content = dict.read()\n",
        "        if \"\\t\" in content:\n",
        "            no_tab_content = content.replace(\"\\t\", \"  \")\n",
        "            with open(user_dict_path, \"w\", encoding = \"utf-8\") as file:\n",
        "                file.write(no_tab_content)\n",
        "        else:\n",
        "            with open(user_dict_path, \"w\", encoding = \"utf-8\") as file:\n",
        "                file.write(content)\n",
        "\n",
        "elif dict_path.endswith(\".yaml\"):\n",
        "    print(\"using yaml format\")\n",
        "    #because they're troublesome >:( (not sure about true and false tho, but ill just include them cus why not)\n",
        "    bool2string = {\n",
        "        \"yes\": \"'yes'\",\n",
        "        \"no\": \"'no'\",\n",
        "        \"on\": \"'on'\",\n",
        "        \"off\": \"'off'\",\n",
        "        \"true\": \"'true'\",\n",
        "        \"false\": \"'false'\"\n",
        "    }\n",
        "\n",
        "    #ik its extra but oh well\n",
        "    with open(dict_path, \"r\", encoding = \"utf-8\") as file:\n",
        "        content = file.read()\n",
        "        for word, replacement in bool2string.items():\n",
        "            pattern = r\"(?<!\\')\\b{}\\b(?!\\')\".format(re.escape(word))\n",
        "            content = re.sub(pattern, replacement, content)\n",
        "    with open(dict_path, \"w\", encoding = \"utf-8\") as file:\n",
        "        file.write(content)\n",
        "\n",
        "    with open(dict_path, \"r\", encoding = \"utf-8\") as dict:\n",
        "        content = yaml.safe_load(dict)\n",
        "        entries = content.get(\"entries\", [])\n",
        "        with open(user_dict_path, \"w\", encoding = \"utf-8\") as file:\n",
        "            for entry in entries:\n",
        "                grapheme = entry[\"grapheme\"]\n",
        "                phonemes = \" \".join(entry[\"phonemes\"])\n",
        "                file.write(f\"{grapheme}  {phonemes}\\n\")\n",
        "else:\n",
        "    raise TypeError(\"format not supported\")\n",
        "\n",
        "graphemes = set()\n",
        "phonemes = set()\n",
        "\n",
        "with open(user_dict_path, \"r\", encoding = \"utf-8\") as file:\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            grapheme = line.split()[0]\n",
        "            graphemes.add(grapheme)\n",
        "            phoneme = line.split(\"  \")[1]\n",
        "            phonemes.update(set(phoneme.split()))\n",
        "\n",
        "#add the necessary stuff ig based on readme\n",
        "\n",
        "required_char = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "\n",
        "#edited this for when theres like special character in dict'''\\\\\n",
        "for char in required_char:\n",
        "    graphemes.discard(char)\n",
        "    phonemes.discard(char)\n",
        "\n",
        "graphemes = required_char + sorted(graphemes)\n",
        "phonemes = required_char + sorted(phonemes)\n",
        "\n",
        "vowel_types = {\"a\", \"i\", \"u\", \"e\", \"o\", \"N\", \"M\", \"NG\"}\n",
        "with open(user_phonemes, \"w\") as f:\n",
        "    for phoneme in phonemes:\n",
        "        if phoneme in required_char:\n",
        "            continue\n",
        "        if phoneme in vowel_types:\n",
        "            f.write(f\"{phoneme}\\tvowel\\n\")\n",
        "        else:\n",
        "            f.write(f\"{phoneme}\\t-\\n\")\n",
        "\n",
        "with open(user_config, \"r\", encoding = \"utf-8\") as cfg:\n",
        "    training_config = yaml.safe_load(cfg)\n",
        "training_config[\"model\"][\"encoder\"][\"graphemes\"] = graphemes\n",
        "training_config[\"model\"][\"decoder\"][\"phonemes\"] = phonemes\n",
        "with open(user_config, \"w\", encoding = \"utf-8\") as cfg:\n",
        "    yaml.dump(training_config, cfg, allow_unicode = True)\n",
        "\n",
        "cfg = user_config\n",
        "cfg = OmegaConf.load(cfg)\n",
        "\n",
        "dataset = user_dict_path\n",
        "dataset = SphinxDataset(dataset, cfg.model,\n",
        "                        comment_prefix=';;;',\n",
        "                        # \"RECORDS(1)\" -> \"RECORDS\"\n",
        "                        remove_word_digits=True,\n",
        "                        # \"R EH1 K ER0 D Z\" -> \"R EH K ER D Z\"\n",
        "                        remove_phoneme_digits=True)\n",
        "\n",
        "# @markdown you may need to adjust the batch size and epochs. <br> If there's too much loss, you can try decreasing the batch size. <br> Between 50 and 150 epochs is generally recommended for training, although you can play around with this a bit. <br> You can continue training from the latest checkpoint at a later moment if you so desire.\n",
        "loss_device = \"cuda\" # @param [\"cpu\", \"cuda\"]\n",
        "batch_size = 128 # @param {type:\"slider\", min:1, max:300, step:1}\n",
        "epochs = 100 # @param {type:\"slider\", min:1, max:300, step:1}\n",
        "\n",
        "\n",
        "#@markdown the model that get saves to save_path will be the g2p-best.ptsd, you can check in g2p folder under /content for other model if applicable"
      ],
      "metadata": {
        "id": "2Ht_ufjfb4T9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start training\n",
        "test_for_error = False # @param {type:\"boolean\"}\n",
        "#@markdown Option to test the finished model for its word error and phoneme error rate.... very slow though, especially with big model (should be in your yaml config)\n",
        "import os\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "#@markdown This wont resume training per se, its just to retry training in case of modified parameters without having to process your dataset again\n",
        "resume = False # @param {\"type\":\"boolean\"}\n",
        "config_path = \"\" # @param {\"type\":\"string\"}\n",
        "base_dir = os.path.dirname(config_path)\n",
        "\n",
        "model_path = os.path.join(base_dir, \"g2p-best.ptsd\")\n",
        "\n",
        "\n",
        "if resume and config_path:\n",
        "    cfg = OmegaConf.load(config_path)\n",
        "    print(f\"Resumed from config: {config_path}\")\n",
        "    print(f\"This wont resume training per se, its just to retry training in case of modified parameters\")\n",
        "else:\n",
        "    # Load from user_config path for new runs\n",
        "    cfg = OmegaConf.load(user_config)\n",
        "    print(f\"Loaded new config: {user_config}\")\n",
        "\n",
        "trainer = G2pTrainer(\n",
        "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "        loss_device=torch.device(\"cpu\"),\n",
        "        model=hydra.utils.instantiate(cfg.model),\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        optimizer_cfg=cfg.get('optimizer', None),\n",
        "        lr_scheduler_cfg=cfg.get('lr_scheduler', None))\n",
        "\n",
        "train(trainer)\n",
        "print(\"Optimizer:\")\n",
        "print(trainer.optimizer)\n",
        "print(\"\\nLearning Rate Scheduler:\")\n",
        "print(trainer.scheduler)\n",
        "print(\"\\nLearning Rate Scheduler State:\")\n",
        "print(trainer.scheduler.state_dict())\n",
        "\n",
        "!cp /content/G2PTrainer/g2p-best.ptsd $save_path\n",
        "\n",
        "if test_for_error:\n",
        "    trainer.test(test_log = save_path +\"/test_log.txt\")\n",
        "else:\n",
        "    pass"
      ],
      "metadata": {
        "id": "8ffFaHTeUwNi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Export ONNX"
      ],
      "metadata": {
        "id": "vr0st7XYV1MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert checkpoint\n",
        "# You can just drop a path and itll appended the file extension\n",
        "model_path = \"path_to_model\" # @param {\"type\":\"string\"}\n",
        "output_path = \"path_to_onnx\" # @param {\"type\":\"string\"}\n",
        "output_path =  output_path + \".onnx\"\n",
        "export(trainer, model_path, output_path)\n"
      ],
      "metadata": {
        "id": "J84E3kR3VbQs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
